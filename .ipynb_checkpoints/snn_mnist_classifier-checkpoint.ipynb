{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SNN MNIST Classifier 📊\n",
    "\n",
    "이 노트북에서는 snnTorch를 사용하여 MNIST 손글씨 숫자 인식을 위한 Spiking Neural Network (SNN)를 구현합니다.\n",
    "\n",
    "## 개요\n",
    "- 정적 이미지(MNIST)를 스파이크 시퀀스로 변환\n",
    "- LIF 뉴런을 사용한 SNN 모델 구축\n",
    "- 스파이크 활동 시각화\n",
    "- M1 Mac MPS 가속 활용"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. 라이브러리 임포트 및 설정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import snntorch as snn\n",
    "from snntorch import utils\n",
    "from snntorch import surrogate\n",
    "from snntorch import functional as SF\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets, transforms\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# 디바이스 설정 (M1 Mac MPS 활용)\n",
    "device = torch.device(\"mps\" if torch.backends.mps.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "# 시각화 설정\n",
    "plt.rcParams['figure.figsize'] = (10, 6)\n",
    "plt.rcParams['font.size'] = 12"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. 하이퍼파라미터 설정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 하이퍼파라미터\n",
    "batch_size = 128\n",
    "data_path = './data'\n",
    "num_steps = 25    # 스파이크 시퀀스 길이 (시간 스텝 수)\n",
    "beta = 0.95       # LIF 뉴런의 멤브레인 전압 감쇠율 (decay rate)\n",
    "num_epochs = 10\n",
    "learning_rate = 5e-4\n",
    "\n",
    "# 네트워크 구조\n",
    "num_inputs = 28*28\n",
    "num_hidden = 100  # 은닉층 뉴런 수\n",
    "num_outputs = 10  # MNIST 클래스 수\n",
    "\n",
    "print(f\"Configuration:\")\n",
    "print(f\"- Batch size: {batch_size}\")\n",
    "print(f\"- Time steps: {num_steps}\")\n",
    "print(f\"- Beta (decay): {beta}\")\n",
    "print(f\"- Hidden neurons: {num_hidden}\")\n",
    "print(f\"- Learning rate: {learning_rate}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. MNIST 데이터 로드 및 전처리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터 변환: 텐서화, 정규화\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.0,), (1.0,))\n",
    "])\n",
    "\n",
    "# MNIST 데이터셋 다운로드 및 로드\n",
    "mnist_train = datasets.MNIST(root=data_path, train=True, download=True, transform=transform)\n",
    "mnist_test = datasets.MNIST(root=data_path, train=False, download=True, transform=transform)\n",
    "\n",
    "train_loader = DataLoader(mnist_train, batch_size=batch_size, shuffle=True)\n",
    "test_loader = DataLoader(mnist_test, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "print(f\"Train dataset size: {len(mnist_train)}\")\n",
    "print(f\"Test dataset size: {len(mnist_test)}\")\n",
    "print(f\"Number of batches: {len(train_loader)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. 데이터 시각화"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 원본 MNIST 이미지 시각화\n",
    "def visualize_mnist_samples(loader, num_samples=8):\n",
    "    \"\"\"MNIST 샘플 이미지들을 시각화합니다.\"\"\"\n",
    "    data_iter = iter(loader)\n",
    "    images, labels = next(data_iter)\n",
    "    \n",
    "    fig, axes = plt.subplots(2, 4, figsize=(12, 6))\n",
    "    axes = axes.ravel()\n",
    "    \n",
    "    for i in range(num_samples):\n",
    "        img = images[i].squeeze().numpy()\n",
    "        axes[i].imshow(img, cmap='gray')\n",
    "        axes[i].set_title(f'Label: {labels[i].item()}')\n",
    "        axes[i].axis('off')\n",
    "    \n",
    "    plt.suptitle('MNIST Sample Images')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "visualize_mnist_samples(train_loader)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. 스파이크 인코딩 및 시각화"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_spike_encoding(image, label, num_steps=25):\n",
    "    \"\"\"이미지의 스파이크 인코딩을 시각화합니다.\"\"\"\n",
    "    # Rate coding을 사용하여 스파이크 시퀀스 생성\n",
    "    # 픽셀 값에 비례하여 스파이크 발생 확률 결정\n",
    "    spike_data = snn.spikegen.rate(image.squeeze(), num_steps=num_steps, gain=1, offset=0)\n",
    "    \n",
    "    fig, axes = plt.subplots(1, 3, figsize=(15, 5))\n",
    "    \n",
    "    # 원본 이미지\n",
    "    axes[0].imshow(image.squeeze().numpy(), cmap='gray')\n",
    "    axes[0].set_title(f'Original Image (Label: {label})')\n",
    "    axes[0].axis('off')\n",
    "    \n",
    "    # 총 스파이크 수 (시간 축으로 합산)\n",
    "    total_spikes = spike_data.sum(dim=0).numpy()\n",
    "    axes[1].imshow(total_spikes, cmap='hot', origin='lower')\n",
    "    axes[1].set_title(f'Total Spike Count\\n(over {num_steps} timesteps)')\n",
    "    axes[1].set_xlabel('Pixel X')\n",
    "    axes[1].set_ylabel('Pixel Y')\n",
    "    \n",
    "    # 특정 픽셀의 스파이크 시퀀스 (중앙 픽셀)\n",
    "    center_pixel_spikes = spike_data[:, 14, 14].numpy()\n",
    "    time_steps = np.arange(num_steps)\n",
    "    axes[2].stem(time_steps, center_pixel_spikes, basefmt=\" \")\n",
    "    axes[2].set_title('Spike Sequence\\n(Center Pixel 14,14)')\n",
    "    axes[2].set_xlabel('Time Step')\n",
    "    axes[2].set_ylabel('Spike (1=fired)')\n",
    "    axes[2].set_ylim(-0.1, 1.1)\n",
    "    axes[2].grid(True, alpha=0.3)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    return spike_data\n",
    "\n",
    "# 첫 번째 이미지로 스파이크 인코딩 시연\n",
    "sample_images, sample_labels = next(iter(train_loader))\n",
    "spike_example = visualize_spike_encoding(sample_images[0], sample_labels[0].item(), num_steps)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. SNN 모델 정의"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SNNNet(nn.Module):\n",
    "    \"\"\"간단한 2층 SNN 모델\"\"\"\n",
    "    \n",
    "    def __init__(self, num_inputs, num_hidden, num_outputs, beta):\n",
    "        super().__init__()\n",
    "        self.num_inputs = num_inputs\n",
    "        self.num_hidden = num_hidden\n",
    "        self.num_outputs = num_outputs\n",
    "        self.beta = beta\n",
    "\n",
    "        # 레이어 정의\n",
    "        self.fc1 = nn.Linear(num_inputs, num_hidden)\n",
    "        self.lif1 = snn.Leaky(beta=self.beta, spike_grad=surrogate.fast_sigmoid())\n",
    "        self.fc2 = nn.Linear(num_hidden, num_outputs)\n",
    "        self.lif2 = snn.Leaky(beta=self.beta, spike_grad=surrogate.fast_sigmoid())\n",
    "\n",
    "    def forward(self, x):\n",
    "        \"\"\"순전파 함수\n",
    "        \n",
    "        Args:\n",
    "            x: 입력 스파이크 시퀀스 (num_steps, batch_size, num_inputs)\n",
    "            \n",
    "        Returns:\n",
    "            cur_out: 출력층의 멤브레인 전압 시퀀스\n",
    "            spk_out: 출력층의 스파이크 시퀀스\n",
    "            spk_hidden: 은닉층의 스파이크 시퀀스 (시각화용)\n",
    "        \"\"\"\n",
    "        # 멤브레인 전압 초기화\n",
    "        mem1 = self.lif1.init_leaky()\n",
    "        mem2 = self.lif2.init_leaky()\n",
    "\n",
    "        cur_list = []  # 출력층 전류 기록\n",
    "        spk_list = []  # 출력층 스파이크 기록\n",
    "        spk_hidden_list = []  # 은닉층 스파이크 기록\n",
    "\n",
    "        # 시간 스텝별 순전파\n",
    "        for step in range(x.size(0)):  # num_steps\n",
    "            cur1 = self.fc1(x[step].view(-1, self.num_inputs))  # Flatten 후 FC1\n",
    "            spk1, mem1 = self.lif1(cur1, mem1)  # LIF 뉴런 1\n",
    "            cur2 = self.fc2(spk1)  # FC2\n",
    "            spk2, mem2 = self.lif2(cur2, mem2)  # LIF 뉴런 2\n",
    "\n",
    "            cur_list.append(cur2)\n",
    "            spk_list.append(spk2)\n",
    "            spk_hidden_list.append(spk1)\n",
    "\n",
    "        return torch.stack(cur_list, dim=0), torch.stack(spk_list, dim=0), torch.stack(spk_hidden_list, dim=0)\n",
    "\n",
    "# 모델 인스턴스 생성\n",
    "net = SNNNet(num_inputs, num_hidden, num_outputs, beta).to(device)\n",
    "print(f\"Model created with {sum(p.numel() for p in net.parameters())} parameters\")\n",
    "print(net)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. 학습 설정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 옵티마이저 및 손실 함수\n",
    "optimizer = torch.optim.Adam(net.parameters(), lr=learning_rate, betas=(0.9, 0.999))\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "\n",
    "# 학습 기록용 변수\n",
    "loss_hist = []\n",
    "test_acc_hist = []\n",
    "train_acc_hist = []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. 평가 함수 정의"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(net, data_loader, device, num_steps):\n",
    "    \"\"\"모델 성능 평가 함수\"\"\"\n",
    "    net.eval()\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for images, labels in data_loader:\n",
    "            # 스파이크 시퀀스 생성 (간단한 반복 방식)\n",
    "            spike_data = images.unsqueeze(0).repeat(num_steps, 1, 1, 1, 1).to(device)\n",
    "            labels = labels.to(device)\n",
    "            \n",
    "            # 순전파\n",
    "            cur_out, spk_out, _ = net(spike_data)\n",
    "            \n",
    "            # 예측 (총 스파이크 수 기반)\n",
    "            total_spikes = spk_out.sum(dim=0)  # 시간 축으로 합산\n",
    "            _, predicted = total_spikes.max(1)\n",
    "            \n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "    \n",
    "    return correct / total\n",
    "\n",
    "def print_batch_accuracy(net, images, labels, device, num_steps, train=False):\n",
    "    \"\"\"배치 정확도 출력 함수\"\"\"\n",
    "    accuracy = evaluate_single_batch(net, images, labels, device, num_steps)\n",
    "    if train:\n",
    "        print(f\"  Batch Accuracy: {accuracy * 100:.2f}%\")\n",
    "    return accuracy\n",
    "\n",
    "def evaluate_single_batch(net, images, labels, device, num_steps):\n",
    "    \"\"\"단일 배치 평가\"\"\"\n",
    "    net.eval()\n",
    "    with torch.no_grad():\n",
    "        spike_data = images.unsqueeze(0).repeat(num_steps, 1, 1, 1, 1).to(device)\n",
    "        labels = labels.to(device)\n",
    "        \n",
    "        cur_out, spk_out, _ = net(spike_data)\n",
    "        total_spikes = spk_out.sum(dim=0)\n",
    "        _, predicted = total_spikes.max(1)\n",
    "        \n",
    "        accuracy = (predicted == labels).sum().item() / labels.size(0)\n",
    "    net.train()\n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. 학습 루프"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Starting training...\")\n",
    "print(f\"Device: {device}\")\n",
    "print(\"-\" * 50)\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    net.train()\n",
    "    epoch_loss = 0\n",
    "    num_correct = 0\n",
    "    num_samples = 0\n",
    "    \n",
    "    for i, (images, labels) in enumerate(train_loader):\n",
    "        # 스파이크 시퀀스 생성 (간단한 반복 방식)\n",
    "        # 실제로는 snn.spikegen.rate()를 사용할 수 있음\n",
    "        spike_data = images.unsqueeze(0).repeat(num_steps, 1, 1, 1, 1).to(device)\n",
    "        labels = labels.to(device)\n",
    "\n",
    "        # 기울기 초기화\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # 순전파\n",
    "        cur_out, spk_out, spk_hidden = net(spike_data)\n",
    "\n",
    "        # 손실 계산 (총 스파이크 수 기반)\n",
    "        loss = loss_fn(spk_out.sum(dim=0), labels)\n",
    "\n",
    "        # 역전파 및 최적화\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # 통계 업데이트\n",
    "        epoch_loss += loss.item()\n",
    "        loss_hist.append(loss.item())\n",
    "        \n",
    "        # 정확도 계산\n",
    "        with torch.no_grad():\n",
    "            total_spikes = spk_out.sum(dim=0)\n",
    "            _, predicted = total_spikes.max(1)\n",
    "            num_correct += (predicted == labels).sum().item()\n",
    "            num_samples += labels.size(0)\n",
    "\n",
    "        # 진행 상황 출력\n",
    "        if (i + 1) % 100 == 0:\n",
    "            batch_acc = (predicted == labels).sum().item() / labels.size(0)\n",
    "            print(f\"Epoch {epoch+1}/{num_epochs}, Step {i+1}/{len(train_loader)}\")\n",
    "            print(f\"  Loss: {loss.item():.4f}, Batch Acc: {batch_acc*100:.2f}%\")\n",
    "\n",
    "    # 에포크 종료 시 평가\n",
    "    train_accuracy = num_correct / num_samples\n",
    "    test_accuracy = evaluate_model(net, test_loader, device, num_steps)\n",
    "    \n",
    "    train_acc_hist.append(train_accuracy)\n",
    "    test_acc_hist.append(test_accuracy)\n",
    "    \n",
    "    print(f\"\\nEpoch {epoch+1} Results:\")\n",
    "    print(f\"  Average Loss: {epoch_loss/len(train_loader):.4f}\")\n",
    "    print(f\"  Train Accuracy: {train_accuracy*100:.2f}%\")\n",
    "    print(f\"  Test Accuracy: {test_accuracy*100:.2f}%\")\n",
    "    print(\"-\" * 50)\n",
    "\n",
    "print(\"Training completed!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. 학습 결과 시각화"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 학습 과정 시각화\n",
    "fig, axes = plt.subplots(1, 3, figsize=(18, 5))\n",
    "\n",
    "# 손실 그래프\n",
    "axes[0].plot(loss_hist)\n",
    "axes[0].set_title(\"Training Loss\")\n",
    "axes[0].set_xlabel(\"Iteration\")\n",
    "axes[0].set_ylabel(\"Loss\")\n",
    "axes[0].grid(True, alpha=0.3)\n",
    "\n",
    "# 정확도 그래프\n",
    "epochs_range = range(1, num_epochs + 1)\n",
    "axes[1].plot(epochs_range, [acc*100 for acc in train_acc_hist], 'b-', label='Train Accuracy')\n",
    "axes[1].plot(epochs_range, [acc*100 for acc in test_acc_hist], 'r-', label='Test Accuracy')\n",
    "axes[1].set_title(\"Accuracy per Epoch\")\n",
    "axes[1].set_xlabel(\"Epoch\")\n",
    "axes[1].set_ylabel(\"Accuracy (%)\")\n",
    "axes[1].legend()\n",
    "axes[1].grid(True, alpha=0.3)\n",
    "\n",
    "# 최종 성능 표시\n",
    "final_train_acc = train_acc_hist[-1] * 100\n",
    "final_test_acc = test_acc_hist[-1] * 100\n",
    "axes[2].bar(['Train', 'Test'], [final_train_acc, final_test_acc], \n",
    "           color=['blue', 'red'], alpha=0.7)\n",
    "axes[2].set_title(\"Final Accuracy\")\n",
    "axes[2].set_ylabel(\"Accuracy (%)\")\n",
    "axes[2].set_ylim(0, 100)\n",
    "\n",
    "# 값 표시\n",
    "axes[2].text(0, final_train_acc + 1, f'{final_train_acc:.1f}%', \n",
    "            ha='center', va='bottom', fontweight='bold')\n",
    "axes[2].text(1, final_test_acc + 1, f'{final_test_acc:.1f}%', \n",
    "            ha='center', va='bottom', fontweight='bold')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(f\"\\nFinal Results:\")\n",
    "print(f\"Train Accuracy: {final_train_acc:.2f}%\")\n",
    "print(f\"Test Accuracy: {final_test_acc:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 11. 스파이크 활동 시각화"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_spike_activity(net, images, labels, device, num_steps, sample_idx=0):\n",
    "    \"\"\"특정 샘플에 대한 스파이크 활동 시각화\"\"\"\n",
    "    net.eval()\n",
    "    \n",
    "    # 단일 샘플 선택\n",
    "    sample_image = images[sample_idx:sample_idx+1]\n",
    "    sample_label = labels[sample_idx:sample_idx+1]\n",
    "    \n",
    "    # 스파이크 시퀀스 생성\n",
    "    spike_data = sample_image.unsqueeze(0).repeat(num_steps, 1, 1, 1, 1).to(device)\n",
    "    sample_label = sample_label.to(device)\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        cur_out, spk_out, spk_hidden = net(spike_data)\n",
    "    \n",
    "    # CPU로 이동\n",
    "    spk_out_cpu = spk_out.cpu().numpy()  # (num_steps, batch_size, num_outputs)\n",
    "    spk_hidden_cpu = spk_hidden.cpu().numpy()  # (num_steps, batch_size, num_hidden)\n",
    "    \n",
    "    fig, axes = plt.subplots(2, 2, figsize=(15, 10))\n",
    "    \n",
    "    # 원본 이미지\n",
    "    axes[0,0].imshow(sample_image.squeeze().numpy(), cmap='gray')\n",
    "    axes[0,0].set_title(f'Input Image (Label: {sample_label.item()})')\n",
    "    axes[0,0].axis('off')\n",
    "    \n",
    "    # 출력 뉴런 스파이크 활동\n",
    "    output_spikes = spk_out_cpu[:, 0, :].T  # (num_outputs, num_steps)\n",
    "    im1 = axes[0,1].imshow(output_spikes, cmap='Greys', aspect='auto')\n",
    "    axes[0,1].set_title('Output Neuron Spikes')\n",
    "    axes[0,1].set_xlabel('Time Step')\n",
    "    axes[0,1].set_ylabel('Output Neuron Index (0-9)')\n",
    "    axes[0,1].set_yticks(range(10))\n",
    "    plt.colorbar(im1, ax=axes[0,1], label='Spike (1=fired)')\n",
    "    \n",
    "    # 은닉층 뉴런 스파이크 활동 (처음 20개만)\n",
    "    hidden_spikes = spk_hidden_cpu[:, 0, :20].T  # (20, num_steps)\n",
    "    im2 = axes[1,0].imshow(hidden_spikes, cmap='Greys', aspect='auto')\n",
    "    axes[1,0].set_title('Hidden Layer Spikes (first 20 neurons)')\n",
    "    axes[1,0].set_xlabel('Time Step')\n",
    "    axes[1,0].set_ylabel('Hidden Neuron Index')\n",
    "    plt.colorbar(im2, ax=axes[1,0], label='Spike (1=fired)')\n",
    "    \n",
    "    # 출력 뉴런별 총 스파이크 수\n",
    "    total_spikes_per_neuron = output_spikes.sum(axis=1)\n",
    "    predicted_label = np.argmax(total_spikes_per_neuron)\n",
    "    \n",
    "    bars = axes[1,1].bar(range(10), total_spikes_per_neuron)\n",
    "    axes[1,1].set_title(f'Total Spikes per Output Neuron\\n(Predicted: {predicted_label})')\n",
    "    axes[1,1].set_xlabel('Output Neuron Index')\n",
    "    axes[1,1].set_ylabel('Total Spikes')\n",
    "    axes[1,1].set_xticks(range(10))\n",
    "    \n",
    "    # 예측된 클래스 강조\n",
    "    bars[predicted_label].set_color('red')\n",
    "    bars[sample_label.item()].set_edgecolor('blue')\n",
    "    bars[sample_label.item()].set_linewidth(3)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    return predicted_label == sample_label.item()\n",
    "\n",
    "# 테스트 샘플들에 대한 스파이크 활동 시각화\n",
    "test_images, test_labels = next(iter(test_loader))\n",
    "\n",
    "print(\"Visualizing spike activity for test samples...\")\n",
    "for i in range(min(3, len(test_images))):\n",
    "    print(f\"\\nSample {i+1}:\")\n",
    "    is_correct = visualize_spike_activity(net, test_images, test_labels, device, num_steps, i)\n",
    "    print(f\"Prediction {'correct' if is_correct else 'incorrect'}!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 12. 모델 저장"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모델 저장\n",
    "model_path = 'snn_mnist_model.pth'\n",
    "torch.save({\n",
    "    'model_state_dict': net.state_dict(),\n",
    "    'optimizer_state_dict': optimizer.state_dict(),\n",
    "    'loss_hist': loss_hist,\n",
    "    'train_acc_hist': train_acc_hist,\n",
    "    'test_acc_hist': test_acc_hist,\n",
    "    'hyperparameters': {\n",
    "        'num_inputs': num_inputs,\n",
    "        'num_hidden': num_hidden,\n",
    "        'num_outputs': num_outputs,\n",
    "        'beta': beta,\n",
    "        'num_steps': num_steps,\n",
    "        'learning_rate': learning_rate\n",
    "    }\n",
    "}, model_path)\n",
    "\n",
    "print(f\"Model saved to {model_path}\")\n",
    "print(f\"Final test accuracy: {test_acc_hist[-1]*100:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 결론\n",
    "\n",
    "이 노트북에서는 snnTorch를 사용하여 MNIST 손글씨 숫자 인식을 위한 기본적인 SNN을 구현했습니다.\n",
    "\n",
    "### 주요 학습 내용:\n",
    "1. **스파이크 인코딩**: 정적 이미지를 스파이크 시퀀스로 변환\n",
    "2. **LIF 뉴런**: Leaky Integrate-and-Fire 뉴런의 동작 원리\n",
    "3. **시간 역학**: SNN에서 시간 차원의 중요성\n",
    "4. **스파이크 기반 학습**: 대리 기울기를 통한 역전파\n",
    "5. **시각화**: 스파이크 활동 패턴 분석\n",
    "\n",
    "### 개선 방향:\n",
    "- 더 정교한 스파이크 인코딩 기법 (Rate coding, Temporal coding)\n",
    "- 다양한 뉴런 모델 (Synaptic, RSynaptic 등)\n",
    "- CNN 구조와의 결합\n",
    "- 실제 뉴로모픽 데이터셋 (N-MNIST, DVS 등) 활용"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}